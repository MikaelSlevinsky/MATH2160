\documentclass[11pt,letterpaper]{article}
\input{../header}

\usepackage{longtable}

\begin{document}
\title{MATH 2160, Chapter 2 Summary \& Exercises}
\author{Richard M. Slevinsky}
\date{}
\maketitle

\section*{A Conversation with Slevinsky}

\begin{longtable}{p{0.475\textwidth}|p{0.475\textwidth}}
\hline
Problems & Solutions\\
\hline
$Ax = b$, $A$ square. & A good algorithm is Gaussian elimination. It is a direct algorithm that terminates after $\OO(n^3)$ operations. Partial pivoting ensures that it is stable; however, there are corner cases where the rounding errors can accumulate {\em geometrically} with the problem dimension.\\
$Ax = b$, $A$ square and multiple RHS. & First, compute a matrix factorization, such as $LUP$ or $QR$. Each of these costs $\OO(n^3)$ operations, but solution of linear systems with factorizations consisting of triangular or orthogonal matrices costs only $\OO(n^2)$ operations.\\
$Ax = b$, $A$ rectangular with more rows than columns. & This is a least-squares problem. DO NOT SOLVE $A^* A x = A^* b$. Instead, use a reduced $QR$ factorization, where $Q$ is now a rectangular matrix with orthonormal columns and $R$ is still square and upper triangular.\\
$Ax = b$, $A$ rectangular with more columns than rows. & Focus! We didn't study this! This is an ill-posed problem, but it is useful in image compression.\\
$A = V\Lambda V^{-1}$? & Generically, a matrix is not guaranteed to have a spectral decomposition.\\
Fine, what about when $A\in\R^{n\times n}$ is symmetric? & Yes! Even better, the eigenvectors can be chosen to be orthonormal: $A = Q\Lambda Q^\top$.\\
$A = U\Sigma V^*$? & Yes! Every matrix $A\in\C^{m\times n}$ has a singular value decomposition.\\
Cool, but why is this useful? & For one, we now know how to calculate the matrix $2$-norm, since $\norm{A}_2 = \sigma_1$, its largest singular value. For another, if we just take the first $r$ columns of $U$ and $V$ and the $r\times r$ principal submatrix of $\Sigma$, we have the best rank-$r$ approximation to $A$, which is another useful matrix compression technique.\\
What happens when $A$ is large? & The main lessons of this chapter are to take advantage of structure of your linear system; structure usually transpires from the problem you are trying to solve. Important structures are symmetry, sparsity patterns, and definiteness, which are all useful when solving linear systems iteratively.\\
\hline
\end{longtable}

\section*{Exercises}

\begin{enumerate}

\item What can we say about the eigenvalues of a unitary matrix?

\item Determine the SVDs of the following matrices (by hand):
\[
\begin{bmatrix} 3 & 0\\ 0 & -2\end{bmatrix},\qquad \begin{bmatrix} 2 & 0\\ 0 & 0\\ 0 & 3\end{bmatrix},\qquad \begin{bmatrix} 1 & 1\\1 & 1\end{bmatrix},\quad{\rm and}\quad \begin{bmatrix} 1 & 2\\2 & 3\end{bmatrix}.
\]

\item Let $\rho(A)$ denote the {\em spectral radius} of $A\in\C^{n\times n}$, i.e. the largest eigenvalue in absolute value $\abs{\lambda}$. Let $\norm{\cdot}_p$ denote the $p$-norm on $\C^n$ and the induced matrix norm on $\C^{n\times n}$. Show that $\rho(A) \le \norm{A}_p$ for every $1\le p\le\infty$.

\item Suppose $A\in\R^{m\times n}$ and $B\in\R^{n\times m}$ is the matrix obtained by rotating $A$ clockwise $90^{\circ}$. Do $A$ and $B$ have the same singular values? Prove that the answer is yes or give a counterexample.

\item The matrix:
\[
A = \frac{1}{2}\begin{bmatrix} 1 & 1\\ & \ddots & \ddots\\ & & 1 & 1\\ 1 & & & 1\\\end{bmatrix} = \frac{1}{2}(I_n+S_n)\in\R^{n\times n}
\]
represents the averaging of the coordinates of an $n$-sided polygon in a plane. Here, $I_n$ is the identity matrix and $S_n$ is the right-circular shift matrix. Although $A$ is not symmetric, it does have a spectral decomposition. Can you find it?

\item Consider the matrix:
\[
A = \begin{bmatrix} 1 & 2\\ & \ddots & \ddots\\ & & 1 & 2\\ & & & 1\end{bmatrix} \in \R^{n\times n}.
\]
\begin{enumerate}
\item What are the eigenvalues and determinant of $A$?
\item What is $A^{-1}$?
\item Give a nontrivial bounds on $\sigma_1$ and $\sigma_n$, the first and last singular values of $A$. Use {\sc Julia} to build your intuition on the problem, but the bounds should be derived analytically.
\end{enumerate}

\end{enumerate}

\end{document}